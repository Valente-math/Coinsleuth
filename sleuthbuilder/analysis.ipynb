{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "import ultimate_sleuthbuilder as usb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "\n",
    "# Set parameters\n",
    "N = 32 # Sequence length\n",
    "sample_size = 100 # Sample size\n",
    "trials = 1000 # Number of trials\n",
    "\n",
    "test_string = \"00111110010100001110010000111110\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sampling distribution of p-values (single core)\n",
    "usb.set_use_db(True)\n",
    "statistics_df = usb.get_statistics(N)\n",
    "\n",
    "mean_p_values = []\n",
    "for trial in range(trials):\n",
    "    # Generate a sample of n random sequences of length N\n",
    "    sequences = [''.join(np.random.choice(['0', '1'], N)) for _ in range(sample_size)]\n",
    "    p_values = []\n",
    "    for seq in sequences:\n",
    "        sample_stats = usb.analyze_sequence(seq, statistics_df)\n",
    "        p_values.append(sample_stats['p_value'])\n",
    "    # sample_df = usb.analyze_sequence_set(sequences)\n",
    "    mean_p_values.append(np.mean(p_values))\n",
    "\n",
    "# mean_p_values = np.array(mean_p_values)\n",
    "sampling_distribution = pd.DataFrame(mean_p_values, columns=['Mean P-value'])\n",
    "\n",
    "# Save to csv\n",
    "sampling_distribution.to_csv('data/mean_p_values_v1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores available: 4\n"
     ]
    }
   ],
   "source": [
    "# Generate sampling distribution of p-values (multi-core)\n",
    "\n",
    "print(f'Number of cores available: {os.cpu_count()}')\n",
    "\n",
    "usb.set_use_db(True)\n",
    "statistics_df = usb.get_statistics(N)\n",
    "# usb.set_use_db(False)\n",
    "\n",
    "# Top-level function to run a single trial (wrapper for ProcessPoolExecutor)\n",
    "def perform_trial(args):\n",
    "    sample_size, N = args\n",
    "    sequences = [''.join(np.random.choice(['0', '1'], N)) for _ in range(sample_size)]\n",
    "    p_values = []\n",
    "    for seq in sequences:\n",
    "        sample_stats = usb.analyze_sequence(seq, statistics_df)\n",
    "        p_values.append(sample_stats['p_value'])\n",
    "    # sample_df = usb.analyze_sequence_set(sequences)\n",
    "    # return sample_df['p_value'].mean()\n",
    "    return np.mean(p_values)\n",
    "\n",
    "# Function to run all trials\n",
    "def run_trials(trials, sample_size, N):\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        mean_p_values = list(executor.map(perform_trial, [(sample_size, N) for _ in range(trials)]))\n",
    "    return mean_p_values\n",
    "\n",
    "# Run trials\n",
    "mean_p_values = run_trials(trials, sample_size, N)\n",
    "\n",
    "# Save results to csv\n",
    "sampling_distribution = pd.DataFrame(mean_p_values, columns=['Mean P-value'])\n",
    "sampling_distribution.to_csv('data/mean_p_values.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate margin of error for various confidence levels\n",
    "\n",
    "db_path = usb.get_db_path()  # Get the path to the database\n",
    "key = usb.get_db_key('summary/p_value')\n",
    "\n",
    "z_scores = {0.90 : 1.645, 0.95 : 1.960, 0.99 : 2.576, 0.999 : 3.291}\n",
    "confidence_levels = z_scores.keys()\n",
    "margin_of_errors = {level : [] for level in confidence_levels}\n",
    "for level in confidence_levels:\n",
    "    # Open the hd5 database at usb.get_db_path()\n",
    "\n",
    "    with pd.HDFStore(db_path, mode='r') as store:  # Open the store in append mode\n",
    "        summary_df = store[key]\n",
    "        \n",
    "        # Get standard deviation for sequences of length N\n",
    "        std_dev = summary_df.loc[N, 'std_dev']\n",
    "        margin_of_error = z_scores[level] * std_dev / np.sqrt(sample_size)\n",
    "        margin_of_errors[level].append(margin_of_error)\n",
    "\n",
    "print('Margin of Error for Various Confidence Levels')\n",
    "for level in confidence_levels:\n",
    "    print(f'{level} confidence level: {margin_of_errors[level]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coin-sleuth-tRbDaKlX-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
